{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from torch import nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StatsPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StatsPooling,self).__init__()\n",
    "\n",
    "    def forward(self,varient_length_tensor):\n",
    "        mean = varient_length_tensor.mean(dim=2)\n",
    "        std = varient_length_tensor.std(dim=2)\n",
    "        return torch.cat((mean,std),dim=1)\n",
    "\n",
    "class Xvector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Xvector, self).__init__()\n",
    "        context = [-2,2]\n",
    "        input_dim = 24\n",
    "        output_dim = 512\n",
    "        self.net1 = TDNN(context, input_dim, output_dim, full_context=True)\n",
    "\n",
    "        context = [-2,0,2]\n",
    "        input_dim = 512\n",
    "        output_dim = 512\n",
    "        self.net2 = TDNN(context, input_dim, output_dim, full_context=False)\n",
    "\n",
    "        context = [-3,0,3]\n",
    "        input_dim = 512\n",
    "        output_dim = 512\n",
    "        self.net3 = TDNN(context, input_dim, output_dim, full_context=False)\n",
    "\n",
    "        context = [0]\n",
    "        input_dim = 512\n",
    "        output_dim = 512\n",
    "        self.net4 = TDNN(context, input_dim, output_dim, full_context=True)\n",
    "\n",
    "        context = [0]\n",
    "        input_dim = 512\n",
    "        output_dim = 1500\n",
    "        self.net5 = TDNN(context, input_dim, output_dim, full_context=True)\n",
    "\n",
    "        self.SP = StatsPooling()\n",
    "        self.hidden1 = nn.Linear(3000,512).double()\n",
    "        self.hidden2 = nn.Linear(512,512).double()\n",
    "\n",
    "        self.Final = nn.Linear(512,len(clases)).double()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.net1(x)\n",
    "        x = self.net2(x)\n",
    "        x = self.net3(x)\n",
    "        x = self.net4(x)\n",
    "        x = self.net5(x)\n",
    "        x = self.SP(x).double()\n",
    "        embedding = F.relu(self.hidden1(x))\n",
    "        embedding = F.relu(self.hidden2(embedding))\n",
    "        return self.Final(embedding) ,embedding\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Xvector(\n",
       "  (net1): TDNN(\n",
       "    (temporal_conv): Conv1d(24, 512, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (net2): TDNN(\n",
       "    (temporal_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), dilation=(2,))\n",
       "  )\n",
       "  (net3): TDNN(\n",
       "    (temporal_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), dilation=(3,))\n",
       "  )\n",
       "  (net4): TDNN(\n",
       "    (temporal_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (net5): TDNN(\n",
       "    (temporal_conv): Conv1d(512, 1500, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (SP): StatsPooling()\n",
       "  (hidden1): Linear(in_features=3000, out_features=512, bias=True)\n",
       "  (hidden2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (Final): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_xvec = torch.load(\"model\")\n",
    "net_xvec.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_path = r\"D:\\Downloads\\Lecture 1.2 — Introduction Supervised Learning — [ Machine Learning  Andrew Ng ].wav\"\n",
    "max_total_context_test = 400\n",
    "_min,_max = float('inf'),-float('inf')\n",
    "X_test = []\n",
    "rate, wav = wavfile.read(wav_path)\n",
    "for chunked_wav in tqdm(chunks(wav,int(len(wav)/4))):\n",
    "    X_sample = mfcc(chunked_wav,samplerate= rate,numcep=24\n",
    "           ,nfilt=26,nfft=1024)\n",
    "    _min = min(np.amin(X_sample),_min)\n",
    "    _max = max(np.amax(X_sample),_max)\n",
    "    for chunked_X_sample in list(chunks(X_sample,max_total_context_test)):\n",
    "            if len(chunked_X_sample) == max_total_context_test:\n",
    "                X_test.append(chunked_X_sample)\n",
    "X_test = (X_test - _min) / (_max-_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_outout = net_xvec(torch.tensor(X_test[200:230]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_ng_output = ng_outout.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvecs_collection = {0:[],1:[],2:[],3:[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    a = time.time()\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    output= net_xvec(inputs).cuda()\n",
    "    for j,out in enumerate(output):\n",
    "        index_to_append = int(torch.argmax(labels[j]))\n",
    "        xvecs_collection[index_to_append].append(out.detach().cpu().numpy())\n",
    "        print ('appending to {}'.format(index_to_append))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"D:\\ml+dl+dsp\\xvector\\celebs_xvectors\",'rb') as f:\n",
    "    xvecs_collection= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clases = ['Trump','Macron','Gaga','Clinton','Andrew_ng']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for class_num in range(len(xvecs_collection)):\n",
    "    for item in xvecs_collection[class_num]:\n",
    "        X.append(item)\n",
    "        y.append(class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add untrained andrew ng to the test set\n",
    "for item in np_ng_output:\n",
    "    X.append(item)\n",
    "    y.append(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = lda.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_X= lda_model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clases_dict = {0:[],1:[],2:[],3:[],4:[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in enumerate(transformed_X):\n",
    "    clases_dict[y[i]].append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in clases_dict:\n",
    "    plt.scatter(np.array(clases_dict[index])[:,0],np.array(clases_dict[index])[:,1])\n",
    "plt.legend(clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "for index in clases_dict:\n",
    "    ax.scatter(np.array(clases_dict[index])[:,0],np.array(clases_dict[index])[:,1],np.array(clases_dict[index])[:,2])\n",
    "plt.legend(clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
