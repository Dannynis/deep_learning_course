{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oku34a34N2cR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from python_speech_features import mfcc, logfbank\n",
    "from tqdm import tqdm \n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AA6PZEzBN2ci"
   },
   "outputs": [],
   "source": [
    "from tdnn import TDNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statstical pooling implementation\n",
    "#### implement a module that takes a matrix and calculates mean and std \n",
    "#### of each channel (y axis) and concatinates them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iMVzRck5N2cu"
   },
   "outputs": [],
   "source": [
    "########################\n",
    "#    your code here    #\n",
    "########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yk6wwv5BN2c3"
   },
   "source": [
    " ## Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lFhgKMwXN2c6"
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aKAa93W2N2dD"
   },
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    return np.eye(num_classes, dtype='uint8')[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zq18P6AeN2dL"
   },
   "outputs": [],
   "source": [
    "clases = ['Trump','Macron','Gaga','Clinton']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is a code that extracts mfcc for training\n",
    "#### write a code that extracts mffcc (using the correct number of features) \n",
    "#### from chunked wav and updates the global _min and _max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8uSQk5LSN2dR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "max_total_context = 400\n",
    "_min,_max = float('inf'),-float('inf')\n",
    "\n",
    "for wav_name in os.listdir('train'):\n",
    "    if wav_name.endswith('wav'):\n",
    "        print (wav_name)\n",
    "        rate, wav = wavfile.read(r'train/'+wav_name)\n",
    "        for chunked_wav in tqdm(chunks(wav,int(len(wav)/4))):\n",
    "            #######################################\n",
    "            #\n",
    "            #          your code here               \n",
    "            #\n",
    "            \n",
    "            for chunked_X_sample in list(chunks(X_sample,max_total_context)):\n",
    "                if len(chunked_X_sample) == max_total_context:\n",
    "                    X.append(chunked_X_sample)\n",
    "                    y.append(to_categorical(clases.index(wav_name.split('.wav')[0]),len(clases)))\n",
    "                else:\n",
    "                    print ('discarded box')\n",
    "X = (X - _min) / (_max-_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### is the amound of data of each speaker is equal ?\n",
    "#### Make an attempt to fix it if so "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.argmax(y,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_data.pkl','wb') as f:\n",
    "    pickle.dump((X,y),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lJpoMA2QN2dX"
   },
   "outputs": [],
   "source": [
    "with open('X_data.pkl','rb') as f:\n",
    "    X,y =  pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-F6AKTHN2dg"
   },
   "outputs": [],
   "source": [
    "\n",
    "trainloader = torch.utils.data.DataLoader(list(zip(X,y)), shuffle=True, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xvector implementation\n",
    "#### Notice that the TDNN layer is already implemented, read the documentation in the file\n",
    "#### tdnn.py, use the context in the paper we used (as printed in the slides) and build the complete Xvector \n",
    "#### architecture.\n",
    "#### *Make sure you can get the embedding easly from the architecture*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "#    your code here    #\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EeqGwZypN2ed"
   },
   "outputs": [],
   "source": [
    "net = Xvector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vq5Gp5T6N2em"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPD2H6MsN2ew"
   },
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model the model that you have implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "q8gYqd5bN2fG",
    "outputId": "97c18643-a4ec-4bfa-d854-c013347e272f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epocs = 300\n",
    "for j in range (epocs):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "            ########################\n",
    "            #    your code here    #\n",
    "            ########################\n",
    "        \n",
    "    print (\"loss: {} step took {}\".format(loss,b-a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "id": "RwtROyKgaX0W",
    "outputId": "2fb4a9dc-a823-49c3-d2e2-d9f92d46082e"
   },
   "outputs": [],
   "source": [
    "  torch.save(net, 'model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BGYV7Z2FN2fm"
   },
   "source": [
    " ### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "McVdE2OsN2fN"
   },
   "outputs": [],
   "source": [
    "xvec = torch.load('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4d8dWMdHN2fr"
   },
   "outputs": [],
   "source": [
    "xvec.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f1fdKsNHN2gE"
   },
   "outputs": [],
   "source": [
    "xvec.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "id": "HZFmrni3N2gJ",
    "outputId": "3edf1869-f446-40ed-ca83-29fe2adf2c8d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wav_path = \"train/Gaga.wav\"\n",
    "max_total_context_test = 400\n",
    "_min,_max = float('inf'),-float('inf')\n",
    "X_test = []\n",
    "rate, wav = wavfile.read(wav_path)\n",
    "for chunked_wav in tqdm(list(chunks(wav,int(len(wav)/400)))[:100]):\n",
    "    X_sample = mfcc(chunked_wav,samplerate= rate,numcep=24\n",
    "           ,nfilt=26,nfft=1024)\n",
    "    _min = min(np.amin(X_sample),_min)\n",
    "    _max = max(np.amax(X_sample),_max)\n",
    "    for chunked_X_sample in list(chunks(X_sample,max_total_context_test)):\n",
    "            if len(chunked_X_sample) == max_total_context_test:\n",
    "                X_test.append(chunked_X_sample)\n",
    "X_test = (X_test - _min) / (_max-_min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVvz9K9oN2gW"
   },
   "source": [
    "## Try the model on the data extracted above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra mission\n",
    "#### extract some x-vectors for the train data and apply LDA dimention reduction to it\n",
    "#### plot the low dimension vectors you got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "xvector_gpu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
